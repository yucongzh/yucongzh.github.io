<!doctype html>
<html>

    <head>
        <meta charset="utf-8"/>
        <title>The Jensen-Shannon Distance</title>
        <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <script>
            MathJax = {
              tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
            };
        </script>
    </head>

    <body>

        <div id="title"><h1>The Jensen-Shannon Distance</h1></div>
    
        <div id="content">

            The Jensen-Shannon Distance is based on the KL divergence, but it is symmetric and it always has a finite value. It is also known as <b>information radius</b> or <b>total divergence to the average</b>. <br>
            
            The square root of the Jensen-Shannon divergence is a metric often refferred to as Jensen-Shannon distance. It has the form below:
                $$JSD(P\| Q)=\frac{1}{2}KL(P\| M)+\frac{1}{2}KL(Q\| M)$$
            where $M=\frac{1}{2}(P+Q)$ <br>

        </div>

        <br>
        <a href="https://yucongzh.github.io/blog_nav.html">back</a>

    </body>

    <!-- <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        $.get('https://yucongzh.github.io/md/test.md', function(response, status, xhr){
            document.getElementById('content').innerHTML = marked.parse(response);
        });
    </script> -->

</html>
