<!doctype html>
<html>
    <head>
        <meta charset="utf-8"/>
        <title>Marked in the browser</title>
    </head>

    <body>
    <div id="content">
        ## testing
        [TOC]

        # Graph Anomaly Detection
        
        ## 1 Background
        
        ### History  
        1. rely heavily on hand-crafted feature engineering
        2. machine learning techniques, such as matrix factorization, SVM
        3. Deep learning approaches
        
        
        
        ### Challenges  
        1. How to effectively separate anomalies from normal objects through training remains
        2. the interpretability of detected anomalies
        3. high training cost
        4. hyperparameter tuning
        
        
        
        ### Preliminaries  
        - Plain graph
        - Attributed graph
        - Dynamic graph
        
        
        
        
        ---
        
        ## 2 Anomalous Node Detection
        
        > 3 types of node anomalies:  global anomalies, structural anomalies and community anomalies.
        
        ![ANOS_ND_overall](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_ND_overall.png)
        
        Non
        
        ### 2.1. On plain graphs
        
        #### 2.1.1 Non-Deep learning techniques
        
        > transform the graph anomaly detection into a traditional anomaly detection problem,  
        > find the suitable feature $\rightarrow$ very difficult
        
        **References:**
        
        - OddBall [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/oddball.pdf)
        
        
        #### 2.1.2 Network representation based techniques
        
        > encode the graph structure into an embedded vector space and identify anomalous nodes through further analysis
        
        **References:**
        
        - An embedding approach [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/embedding_approach.pdf)
        
        
        
        ### 2.2 On attributed graphs
        
        #### 2.2.1 Deep neural network based techniques
        
        > dnns provide solid basis for learning data representations
        
        ![ANOS_ND_attr_dnn](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_ND_attr_dnn.png)
        
        **References:**
        
        - DONE [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Outlier Resistant Unsupervised Deep Architectures for Attributed Network Embedding.pdf)
          - two AEs, one for structure and one for attribute
          - both autoencoders are used to minimize the reconstruction errors and preserving the homophily that assumes connected nodes have similar representations in the graph
          - three anomaly scores: 1) similar attribute? 2) connection? 3) connected but different attribute?
          - top-k nodes with higher scores are identified as anomalies
        
        #### 2.2.2 GCN based techniques
        
        > Excellent capability of capturing comprehensive information
        
        ![ANOS_ND_attr_gcn](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_ND_attr_gcn.png)
        
        **References:**
        
        - DOMINANT [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Deep Anomaly Detection on Attributed Networks.pdf)
          - the graph convolutional encoder, inspired by [SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS](/Users/morgan/Documents/PhD/papers & books/GAD/SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS.pdf)
          - the structure reconstruction decoder 
          - the attribute reconstruction decoder
        - ALARM, capture the multiple attributed views [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/A Deep Multi-View Framework for Anomaly Detection on Attributed Networks.pdf)
          - training strategy is similar to DOMINANT
          - The underlying intuition of investigating different views is that anomalies might appear to be normal in one view but abnormal in another view.
        - SpecAE [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/SpecAE_Spectral AutoEncoder for Anomaly Detection in Attributed Networks.pdf)
          - detect global anomalies and community anomalies via a density estimation approach, GMM
          - global anomalies $\leftarrow$ node attributes (only considered)
          - community anomalies $\leftarrow$ node structure and attributes (jointly considered)
        - Fdgars [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/FdGars_Fraudster Detection via Graph Convolutional Networks in Online App Review System.pdf)
        - GraphRfi [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Gcn-based user representation learning for unifying robust recommendation and fraudster detection.pdf)
        
        #### 2.2.3 Reinforcement learning techniques
        
        > tackling real-world decision making problems
        
        **References:**
        
        - GraphUCB [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Interactive anomaly detection on attributed networks.pdf)
        
        
        
        ### 2.3 On dynamic graphs
        
        #### 2.3.1 Network representation based techniques
        
        > dynamic graphs usually introduce large volume of data and temporal signals should also be captured for anomaly detection
        
        **References:**
        
        - Netwalk [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/NetWalk_A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks.pdf)
          - using only the structural information
          - Detect anomalies $\leftarrow$ streaming *K*-means clustering, anomaly score measured by the closest distance to the clusters
        
        #### 2.3.2 GAN based techniques
        
        > impressive performance in capturing real data distribution and generating simulated data
        
        **References:**
        
        - OCAN [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/One-class adversarial nets for fraud detection.pdf)
          - seize the normal activity patterns and detect anomalies that behave significantly different
          - LSTM-based AE -> features
          - one-class adversarial net comprising a generator and a discriminator
          - the generator produces complementary data points that locate in the relatively low density areas of benign users
          - the discriminator aims to distinguish the generated samples from the benign users
        
        
        
        
        ---
        
        
        ## 3 Anomalous Edge Detection
        
        > aims to identify abnormal links
        >
        > These links often inform the unexpected or unusual relationships between real objects
        
        ### 3.1 On static graphs
        
        #### 3.1.1 DNN based techniques
        
        > autoencoder and fully connected network (FCN) have also been used for anomalous edge detection
        
        ![ANOS_ED_static_dnn](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_ED_static_dnn.png)
        
        **References:**
        
        - model the distribution of edges through deep models  [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Unified Graph Embedding-Based Anomalous Edge Detection.pdf)
          - The probability of each edge $(u,v)$ is decided by $P(v \mid u, N(u))$ and $P(u \mid v, N(v))$.
          - UGED is proposed to calculate $P(v \mid u, N(u))$.
            - Node encoding by a fully connected network $\rightarrow$ low dimension space
            - Then, each node is represented as a mean aggregation of itself and its neighbors' vector
            - Feed the node representations into another fully connected network to estimate $P(v \mid u, N(u))$
          - The anomaly score is calculated by the average of $1-P(v \mid u, N(u))$ and $1-P(u \mid v, N(v))$
        
        #### 3.1.2 GCN based techiniques
        
        > the existence of anomalous edges in the training data prevents traditional GCN based models from capturing real edge distributions
        
        ![ANOS_ED_static_GCN](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_ED_static_GCN.png)
        
        **References:**
        
        - AANE [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/AANE_Anomaly_Aware_Network_Embedding_for_Anomalous_Link_Detection.pdf)
        
          - iteratively updating the embeddings and detection results during training
        
          - In each iteration, use GCN to generate node embeddings $Z$, also learns an indicator matrix $I$ to spot potential anomalous edges.
        
            - each term in the matrix $I$ is determined by (mean - $\mu$ std)
        
          - The total loss function of AANE has two parts:
        
            - an anomaly-aware loss ($\mathcal{L_{aal}}$)
        
            $$
            \mathcal{L}_{a a l}=\sqrt{\sum_{u \in V} \sum_{v \in N(u)}\left(\left(1-\hat{A}_{u v}^{2}\right)\left(1-I_{u v}\right)+\hat{A}_{u v}^{2} I_{u v}\right)}
            $$
        
            ​
        
            - an adjusted fitting loss ($\mathcal{L_{afl}}$), quantifying the reconstruction loss with regard to the removal of potential anomalous edges
        
            $$
            \mathcal{L}_{a f l}=\|B-\hat{A}\|_{2}^{2}
            $$
        
            where B is an adjusted adjacency matrix that removes all predicted anomalies from input adjacency matrix A.
        
        #### 3.1.3 Network represnetation based techniques
        
        > edge representations learned directly from the graph are also feasible for distinguishing anomalies
        
        **References:**
        
        - ICANE [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Icane_Interaction content-aware network embedding via co-embedding of nodes and edges.pdf)
        
        
        
        ### 3.2 On dynamic graphs
        
        #### 3.2.1 Network representation based techniques
        
        > first encode the dynamic graph structure information into edge representations
        >
        > then apply the aforementioned traditional anomaly detection techniques to spot irregular edges
        
        
        
        #### 3.2.2 GCN based techiniques
        
        > combined temporal, structural and attribute information to measure the anomalousness of edges
        
        **References:**
        
        - AddGraph [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/AddGraph_Anomaly Detection in Dynamic Graph Using Attention-based Temporal GCN.pdf)
          - Comprises a GCN and [Gated Recurrent Units (GRU) with attention](/Users/morgan/Documents/PhD/papers & books/GAD/Sequential Recommender System based on Hierarchical Attention Network.pdf) to capture more representative structural information from the temporal graph in each time stamp and dependencies between them, respectively.
        
        
        
        
        ---
        
        ## 4 Anomalous Sub-graph Detection
        
        >In real life, anomalies might also collude and behave collectively with others to garner benefits.
        >
        >Unlike individual and independent graph anomalies, i.e., single nodes or edges, each node and edge in a suspicious sub-graph might be normal. However, when considered as a collection, they turn out to be anomalous.
        
        ![ANOS_SGD_overall](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_SGD_overall.png)
        
        **References:**
        
        - DeepFD [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Deep structure learning for fraud detection.pdf)
          - learn anomaly-aware representations of users such that suspicious users in the same group will be located closely in the vector space, while benign users will be far away
          - observation: user nodes belonging to one fraudulent group are more likely to connect with the same item nodes
          - reconstruction loss + similarity loss + regularization loss
        - FraudNE [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/FraudNE_a_Joint_Embedding_Approach_for_Fraud_Detection.pdf)
          - encode both types of nodes into a shared latent space where suspicious users and items belonging to the same dense block are very close to each other while others distribute uniformly
          - a source node autoencoder + a sink node autoencoder
        
        
        
        
        
        ## 5 Anomalous Graph Detection
        
        >It aims to detect individual graphs that deviate significantly from the others
        >
        >This is commonly approached by:
        >
        >​	1) measuring the pairwise proximities [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Fast memory_efficient anomaly detection in streaming heterogeneous graphs.pdf)
        >
        >​	2) detecting the appearance of anomalous graph signals created by abnormal groups of nodes [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Changedar_Online localized change detection for sensor data on a graph.pdf)
        >
        >​	3) encoding graphs using frequent motifs [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Graph_based anomaly detection.pdf)
        
        
        **(Definition) Graph Database**:
        
        >  A graph database $\mathcal{G}=\{G_i=(V_i,E_i, X_v(i),X_e(i))\}_{i=1}^{N}$ contains $N$ individual graphs. Here, each graph $G_i$ is comprised of a node set $V_i$ and an edge set $E_i$. $X_v(i)$ and $X_e(i)$ are the node attribute matrix and edge attribute matrix of $G_i$ if it is an attributed graph.
        
        ### 5.1 GNN based techniques
        
        > GNN good at graph classification tasks
        >
        > Employ GNNs to classify single graphs as normal/abnormal in the given graph database
        
        **References:**
        
        - fake news detection [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/User preference_aware fake news detection.pdf)
        - employ a GIN model and one-class classification [DeepSVDD](/Users/morgan/Documents/PhD/papers & books/GAD/Deep one_class classification.pdf) loss to train an e2e framework [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/On Using Classification Datasets to Evaluate Graph Outlier Detection_Peculiar Observations and New Insights.pdf)
        
        ### 5.2 Network representation based techniques
        
        > the detection problem is transformed into a conventional outlier detection problem in the embedding space
        >
        > Unlike detecting graph anomalies in an e2e manner, it has two stages:
        >
        > ​	1) graphs in the database are encoded into a shared latent space using graph-level representation 		techiniques.
        >
        > ​	2) the anomalousness of each single graph is measured by an off-the-shelf outlier detector.
        
        ### 5.3 Anomalous graph detection On dynamic graphs
        ![ANOS_GD_overall](/Users/morgan/Documents/PhD/sharing/GAD/imgs/ANOS_GD_overall.png)
        **References:**
        
        - DeepSphere [pdf](/Users/morgan/Documents/PhD/papers & books/GAD/Deep into hypersphere_Robust and unsupervised anomaly discovery in dynamic networks.pdf)
          - Apply a LSTM-autoencoder to detect abnormal graph snapshots
          - DeepSphere first embeds each graph snapshot into a latent space using an LSTM autoencoder, and then leverages a [one-class classification objective](/Users/morgan/Documents/PhD/papers & books/GAD/Deep one_class classification.pdf) that learns a hypersphere such that normal snapshots are covered, and anomalous snapshots lay outside.
          - The LSTM autoencoder takes the adjacency matrices as input sequentially and is trained to reconstruct the input sequence.
          - the hypersphere is learned through a single neural network layer
        
        
         
    </div>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        document.getElementById('content').innerHTML =
        marked.parse('# Marked in the browser\n\nRendered by **marked**.');
    </script>
    </body>
</html>